{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil import parser\n",
    "import pytz\n",
    "from timezonefinder import TimezoneFinder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time, sys\n",
    "import re\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "#%matplotlib inline\n",
    "#https://github.com/MrMinimal64/timezonefinder\n",
    "\n",
    "utc=pytz.UTC\n",
    "\n",
    "#debug = True\n",
    "debug = True\n",
    "filepath = './sample_data/'\n",
    "\n",
    "if debug == False:\n",
    "    gpx_file = input('Enter file name (must be in same directory as this program for now): ')\n",
    "    tree = ET.parse(filepath + gpx_file)\n",
    "else:\n",
    "    tree = ET.parse('./sample_data/Exciter_100.gpx')\n",
    "    #tree = ET.parse('./sample_data/ITPS_out.gpx')\n",
    "    #tree = ET.parse('./sample_data/See_you_later_Winter_welcome_Spring.gpx')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each gps device has its own namespace for recording the GPX file... this function reads the embeded namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namespace(element):\n",
    "    m = re.match('\\{(.*)\\}', element.tag)\n",
    "    return m.group(1) if m else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'http://vortex.plymouth.edu/cgi-bin/sfc/gen-statlog-a.cgi?ident=cyxu&pl=rawspec&yy=19&mm=04&dd=04&pg=web'\n",
    "#dialog http://vortex.plymouth.edu/myo/sfc/statlog-a.html\n",
    "#choose raw hourly & special METAR obs listings\n",
    "#but only valid for us/cn/mx\n",
    "#options\n",
    "#http://www.ogimet.com/metars.phtml.en\n",
    "#http://www.ogimet.com/display_metars2.php?lang=en&lugar=sbsp&tipo=ALL&ord=REV&nil=SI&fmt=html&ano=2019&mes=04&day=04&hora=00&anof=2019&mesf=04&dayf=04&horaf=23&minf=59&send=send\n",
    "\n",
    "#https://www.cyclinganalytics.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#namespace = {'gpx':'http://www.topografix.com/GPX/1/1'}\n",
    "namespace = {'gpx':namespace(root)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def deg2rad(x):\n",
    "    return x * np.pi / 180\n",
    "\n",
    "def rad2deg(angle):\n",
    "    return angle * 180 / np.pi\n",
    "\n",
    "def kt2ms(speed):\n",
    "    return speed * 0.5144444\n",
    "\n",
    "def ms2kmh(speed):\n",
    "    return speed * 3.6\n",
    "\n",
    "def kmh2kt(speed):\n",
    "    return speed / 1.852"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the distance and angle between 2 coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_trk(p2, p1):\n",
    "    #p1 is a list with lat and long in degrees\n",
    "    #p2 is also a list: lat long\n",
    "    #returns distance and angle\n",
    "    #distance in metres\n",
    "    #reference: https://www.movable-type.co.uk/scripts/latlong.html\n",
    "    R = 6371e3 #mean radius of Earth in meters\n",
    "    phi1 = deg2rad(p1[0])\n",
    "    phi2 = deg2rad(p2[0])\n",
    "    lambda1 = deg2rad(p1[1])\n",
    "    lambda2 = deg2rad(p2[1])\n",
    "    delta_phi = phi2 - phi1\n",
    "    delta_lambda = lambda2 - lambda1\n",
    "    a = np.sin(delta_phi / 2) * np.sin(delta_phi / 2) + \\\n",
    "        np.cos(phi1) * np.cos(phi2) * \\\n",
    "        np.sin(delta_lambda / 2) * np.sin(delta_lambda / 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = R * c\n",
    "    y = np.sin(delta_lambda) * np.cos(phi2)\n",
    "    x = np.cos(phi1) * np.sin(phi2) - \\\n",
    "        np.sin(phi1) * np.cos(phi2) * np.cos(delta_lambda)\n",
    "    brg = np.arctan2(y,x) * 180 / np.pi\n",
    "    return d, brg + 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through GPX file for each recorded track point and calculate distance and angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building track database...\n",
      "0%... dt going down: 0.0\n",
      "dt going down: 1.0\n",
      "10%... 20%... 30%... 40%... 50%... 60%... 70%... 80%... 90%... 100%... \n",
      "Track build time was 521.8 seconds\n"
     ]
    }
   ],
   "source": [
    "print('Building track database...')\n",
    "track = pd.DataFrame(columns=['lat', 'lon', 'elev', 'ts', 'dist', 'true_hdg', 'gs', 'delta_t', 'delta_elev'])\n",
    "#lat in deg decimal\n",
    "#lon in deg decimal\n",
    "#elev in meters\n",
    "#ts in datetime, tz=0\n",
    "#dist in meters\n",
    "#true_hdg in degrees\n",
    "#gs in m/s\n",
    "trackpoint = {}\n",
    "debug_counter = 0\n",
    "for trk in root.findall('gpx:trk', namespace):\n",
    "    for trksegmt in trk.findall('gpx:trkseg', namespace):\n",
    "        first_point = True\n",
    "        trk_pts_number = len(trksegmt.findall('gpx:trkpt', namespace))\n",
    "        ten_perc = int(len(trksegmt.findall('gpx:trkpt', namespace)) / 10)\n",
    "        for idx, trkpoint in enumerate(trksegmt.findall('gpx:trkpt', namespace)):\n",
    "            if (idx % ten_perc) == 0:\n",
    "                print('{:0.0f}%... '.format(idx/trk_pts_number*100), end='')\n",
    "            trackpoint['lat'] = float(trkpoint.get('lat'))\n",
    "            trackpoint['lon'] = float(trkpoint.get('lon'))\n",
    "            for elev in trkpoint.findall('gpx:ele', namespace):\n",
    "                #print(elev.text)\n",
    "                trackpoint['elev'] = float(elev.text)\n",
    "            for ts in trkpoint.findall('gpx:time', namespace):\n",
    "                #print(ts.text)\n",
    "                trackpoint['ts'] = parser.parse(ts.text)\n",
    "            if first_point:\n",
    "                previous_point = trackpoint\n",
    "                first_point = False\n",
    "            dist, angle = get_dist_trk([previous_point['lat'],previous_point['lon']], [trackpoint['lat'],trackpoint['lon']])\n",
    "            if debug_counter < 20:\n",
    "                #print(dist, trackpoint['lon'], previous_point['lon'])\n",
    "                debug_counter += 1\n",
    "            \n",
    "            trackpoint['delta_t'] = (trackpoint['ts']-previous_point['ts']).total_seconds()\n",
    "            trackpoint['dist'] = dist\n",
    "            trackpoint['true_hdg'] = angle\n",
    "            if trackpoint['delta_t'] != 0:\n",
    "                trackpoint['gs'] = dist / trackpoint['delta_t']\n",
    "            else:\n",
    "                trackpoint['gs'] = 0\n",
    "                trackpoint['delta_t'] = np.nan\n",
    "            trackpoint['delta_elev'] = (trackpoint['elev']-previous_point['elev'])\n",
    "            previous_point = trackpoint\n",
    "            track = track.append(trackpoint, ignore_index=True)\n",
    "            trackpoint = {}\n",
    "end_time = time.time()\n",
    "print()\n",
    "print('Track build time was {:1.1f} seconds'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas\n",
    "#shift\n",
    "#apply\n",
    "#applymap\n",
    "#run apply on column and use lambda to filter the 2 data points and pass to function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean LAT / LON\n",
    "\n",
    "Find weather stations near the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_distance = 20 #nm\n",
    "print(f'Figuring out nearest weather station...using {radial_distance} nm search radius...')\n",
    "#nearest airport\n",
    "#http://aviationweather.gov/adds/dataserver_current/httpparam?dataSource=stations&requestType=retrieve&format=xml&radialDistance=20;-81.275376,43.024538\n",
    "lon_mean = track['lon'].mean()\n",
    "lat_mean = track['lat'].mean()\n",
    "ride_day = track['ts'][0].day\n",
    "ride_month = track['ts'][0].month\n",
    "ride_year = track['ts'][0].year\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://aviationweather.gov/adds/dataserver_current/httpparam?dataSource=stations&requestType=retrieve' + \\\n",
    "      '&format=xml&radialDistance=' + str(radial_distance) + ';' + str(lon_mean) + ',' + str(lat_mean)\n",
    "\n",
    "source = urllib.request.urlopen(url).read()\n",
    "tree = ET.ElementTree(ET.fromstring(source))\n",
    "root = tree.getroot()\n",
    "station_id_list = []\n",
    "for data in root.findall('data'):\n",
    "    for station in data.findall('Station'):\n",
    "        for station_ident in station.findall('station_id'):\n",
    "            station_id_list.append(station_ident.text)\n",
    "print('Nearest stations are: ', station_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle each station and try to find a METAR\n",
    "\n",
    "If found, then create the weather database\n",
    "\n",
    "If not found, asks user to enter prevailing wind speed and direction (true magnetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ogi_data(station, ride_day, ride_month, ride_year):\n",
    "    '''\n",
    "    retrieve weather data from OGIMET\n",
    "    this site only offers the last 30 days\n",
    "    inputs:\n",
    "        station: (str) - 4 letter code\n",
    "        ride_day, ride_month, ride_year: (int)\n",
    "    returns:\n",
    "        found_data: (bool) true if data was found\n",
    "        metinfo: (list) - parsed data\n",
    "        \n",
    "    site url template:\n",
    "    http://www.ogimet.com/display_metars2.php?lang=en&amp;lugar=CYXU&amp;tipo=ALL&amp;ord=REV&amp;nil=SI&amp;fmt=html&amp;ano=2020&amp;mes=5&amp;day=16&amp;hora=00&amp;anof=2020&amp;mesf=5&amp;dayf=16&amp;horaf=23&amp;minf=59&amp;send=send\n",
    "    http://www.ogimet.com/display_metars2.php?lang=en&lugar=CYXU&tipo=ALL&ord=REV&nil=SI&fmt=html&ano=2020&mes=05&day=16&hora=21&anof=2020&mesf=05&dayf=16&horaf=21&minf=59&send=send\n",
    "    '''\n",
    "\n",
    "    #only try to retrieve data if station is not null\n",
    "    metar_found = False\n",
    "    metar_db = []\n",
    "    if station != '':\n",
    "        url = 'http://www.ogimet.com/display_metars2.php?lang=en&lugar='+str(station)+ \\\n",
    "        '&tipo=ALL&ord=REV&nil=SI&fmt=html&ano='+str(ride_year)+ \\\n",
    "        '&mes='+str(ride_month)+'&day='+str(ride_day)+ \\\n",
    "        '&hora=00&anof='+str(ride_year)+'&mesf='+str(ride_month)+'&dayf='+str(ride_day)+ \\\n",
    "        '&horaf=23&minf=59&send=send'\n",
    "        source = urllib.request.urlopen(url).read()\n",
    "        soup = bs.BeautifulSoup(source, features='html.parser')\n",
    "        table = soup.table\n",
    "        table_rows = table.find_all('tr')\n",
    "        metar_list = []\n",
    "        for tr in table_rows:\n",
    "            td = tr.find_all('td')\n",
    "            row = [i.text for i in td]\n",
    "            metar_list.append(row)\n",
    "        for idx, line in enumerate(metar_list):\n",
    "            #print(idx, line)\n",
    "            for item in line:\n",
    "                found = item.find('METAR '+str(station))\n",
    "                if found != -1:\n",
    "                    metar_found = True\n",
    "                    try:\n",
    "                        mday = int(item[found+11:found+13])\n",
    "                        mhour = int(item[found+13:found+15])\n",
    "                        mminute = int(item[found+15:found+17])\n",
    "                        wind_dir = int(item[found+19:found+22])\n",
    "                        wind_spd = int(item[found+22:found+24])\n",
    "                        metar_station = str(station)\n",
    "                        #print('mday:', mday)\n",
    "                        #print('mhour:', mhour)\n",
    "                        #print('mminute:', mminute)\n",
    "                        #print('wind_dir:', wind_dir)\n",
    "                        #print('wind_spd:', wind_spd)\n",
    "\n",
    "                        metar_db.append([datetime.datetime(year=ride_year, month=ride_month, day=ride_day, \n",
    "                                                           hour=mhour, minute=mminute, second=0, tzinfo=pytz.UTC), \n",
    "                                                           wind_dir, wind_spd])\n",
    "\n",
    "                    except:\n",
    "                        #print('parsing error')\n",
    "                        pass\n",
    "        #naming columns to harmonize with wunder...not my choice\n",
    "        weather_data = pd.DataFrame(columns=['Time', 'Wind_Dir', 'Wind Speed'] , data=metar_db)\n",
    "        weather_data['Time'] = pd.to_datetime(weather_data['Time'])\n",
    "        metinfo_db.set_index('Time')\n",
    "        return metar_found, weather_data\n",
    "    else:\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wunder_data(station, ride_day, ride_month, ride_year):\n",
    "    '''\n",
    "    retrieve weather data from WUNDERGROUND\n",
    "    inputs:\n",
    "        station: (str) - 4 letter code\n",
    "        ride_day, ride_month, ride_year: (int)\n",
    "    returns:\n",
    "        found_data: (bool) true if data was found\n",
    "        metinfo: (pandas.df) - parsed data\n",
    "        \n",
    "    site url template:\n",
    "      https://www.wunderground.com/history/daily/CYXU/date/2004-5-10\n",
    "    '''\n",
    "    \n",
    "    url = 'https://www.wunderground.com/history/daily/'+str(station)+ \\\n",
    "    '/date/' + str(ride_year) + '-' + str(ride_month) + '-'+str(ride_day)\n",
    "\n",
    "    # instantiate webdriver and get data\n",
    "    # you need firefox bynary and the geckodriver installed\n",
    "    # the geckodriver interfaces with firefox to get the page and pass the data back\n",
    "    wd = webdriver.Firefox()\n",
    "    wd.get(url)\n",
    "\n",
    "    soup = bs.BeautifulSoup(wd.page_source, 'lxml')\n",
    "\n",
    "    wd.quit()\n",
    "    \n",
    "    #find all tables\n",
    "    \n",
    "    data_found = False\n",
    "    table_index = 0\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    #find the correct table\n",
    "    for tidx, table in enumerate(tables):\n",
    "        table_head = table.findAll('th')\n",
    "        output_head = []\n",
    "        for head in table_head:\n",
    "            output_head.append(head.text.strip())\n",
    "            if output_head[0] == 'Time':\n",
    "                data_found = True\n",
    "                table_index = tidx\n",
    "    #get the data\n",
    "    \n",
    "    if not data_found:\n",
    "        #if no tables found, return false and an None\n",
    "        return data_found, None\n",
    "    else:\n",
    "\n",
    "        table = tables[table_index]\n",
    "\n",
    "        # parse table - first the header\n",
    "        table_head = table.findAll('th')\n",
    "        output_head = []\n",
    "        for head in table_head:\n",
    "            output_head.append(head.text.strip())\n",
    "\n",
    "        # create empty dataframe\n",
    "        weather_data = pd.DataFrame(columns=output_head)\n",
    "\n",
    "        # parse rows\n",
    "        output_rows = []\n",
    "        rows = table.findAll('tr')\n",
    "        for row in rows:\n",
    "            columns = row.findAll('td')\n",
    "            clean_row = []\n",
    "            for column in columns:\n",
    "                clean_row.append(column.text.strip().replace(u'\\xa0', '') #this is to remove unwanted characters\n",
    "                                 .replace('mph', '') \n",
    "                                 .replace('F', '')\n",
    "                                 .replace('in', ''))\n",
    "            if len(clean_row) > 0: # discard row if it is empty\n",
    "                output_rows.append(clean_row)\n",
    "\n",
    "        # add it all to the dataframe\n",
    "        weather_data = pd.DataFrame(columns=output_head, data=output_rows).apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "        # substitute wind direction for numeric headings\n",
    "        wind_dir_dict = {\"N\":0,\"NNE\":22.5,\"NE\":45,\"ENE\":67.5,\n",
    "                         \"E\":90,\"ESE\":112.5, \"SE\":135, \"SSE\":157.5,\n",
    "                         \"S\":180,\"SSW\":202.5,\"SW\":225,\"WSW\":247.5,\n",
    "                         \"W\":270,\"WNW\":292.5,\"NW\":315,\"NNW\":337.5, \n",
    "                         \"CALM\":0, \"VAR\":0}\n",
    "\n",
    "        weather_data['Wind_Dir'] = weather_data['Wind'].map(wind_dir_dict)\n",
    "\n",
    "        #make time something useful\n",
    "        weather_data['Time'] = pd.to_datetime(weather_data['Time'].apply(lambda x : str(ride_year)+\n",
    "                                                                         '-'+str(ride_month)+\n",
    "                                                                         '-'+str(ride_day)+\n",
    "                                                                         ' '+x))\n",
    "        #harmonize and keep wind speed in kts\n",
    "        weather_data['Wind Speed'] = kmh2kt(weather_data['Wind Speed'])\n",
    "        \n",
    "        return data_found, weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metinfo_found = False\n",
    "datetime.date.today()\n",
    "delta_days = (datetime.date.today() - (track['ts'][0].to_pydatetime()).date()).days\n",
    "\n",
    "station_index = 0\n",
    "while metinfo_found == False and station_index < len(station_id_list):\n",
    "\n",
    "    if delta_days < 30:\n",
    "        #try to get data from ogimet\n",
    "        #if successful set metinfo_found = True\n",
    "        print(f\"Checking if I can find data for station {station_id_list[station_index]} at OGI...\", end='')\n",
    "        \n",
    "        if station_id_list[station_index]!= '':\n",
    "            metinfo_found, metinfo_db = get_ogi_data(station_id_list[station_index], ride_day, ride_month, ride_year)\n",
    "        if metinfo_found:\n",
    "            print(\"found data!\")\n",
    "        else:\n",
    "            print(\"no\")\n",
    "        \n",
    "    if not metinfo_found:\n",
    "        #try to get data from wunder\n",
    "        #if successful, set metinfo_found = True\n",
    "        print(f\"Checking if I can find data for station {station_id_list[station_index]} at Wunder...\", end='')\n",
    "        \n",
    "        if station_id_list[station_index]!= '':\n",
    "            metinfo_found, metinfo_db = get_wunder_data(station_id_list[station_index], ride_day, ride_month, ride_year)\n",
    "        if metinfo_found:\n",
    "            #we neeed to shift the time because Wunder returns local time. We need UTC\n",
    "            tf = TimezoneFinder()\n",
    "            ride_tz = tf.timezone_at(lng=lon_mean, lat=lat_mean)\n",
    "            metinfo_db['Time'] = pd.to_datetime(metinfo_db['Time']).dt.tz_localize(ride_tz).dt.tz_convert('UTC')\n",
    "            \n",
    "            print(\"found data!\")\n",
    "        else:\n",
    "            print(\"no\")\n",
    "            \n",
    "    station_index += 1\n",
    "if not metinfo_found:\n",
    "    #manual entry\n",
    "    print('no auto METAR data')\n",
    "    wind_dir = input('Enter wind direction (true heading): ')\n",
    "    wind_spd = input('Enter wind speed: ')\n",
    "    metinfo_db = pd.DataFrame(columns=['Time', 'Wind_Dir', 'Wind Speed'], data=[datetime.datetime(year=ride_year, month=ride_month, day=ride_day, \n",
    "                                                                                      hour=0, minute=0, second=0, tzinfo=pytz.UTC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the headwind component and stores in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track['ts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Populate wind components...')\n",
    "#create columns\n",
    "track['wind_spd'] = 0\n",
    "track['wind_dir'] = 0\n",
    "\n",
    "#find start\n",
    "index_start = metinfo_db[track['ts'].iloc[0] <= metinfo_db['Time']].index[0]\n",
    "index_end = metinfo_db[track['ts'].iloc[-1] < metinfo_db['Time']].index[0]\n",
    "\n",
    "#find and set values\n",
    "metinfo_indexes = range(index_start, index_end)\n",
    "for metinfo_index in range(index_start, index_end+1):\n",
    "    if metinfo_index == index_start:\n",
    "        track.loc[track['ts'] <= metinfo_db['Time'].iloc[metinfo_index], ['wind_spd']] = metinfo_db['Wind Speed'].iloc[metinfo_index]\n",
    "        track.loc[track['ts'] <= metinfo_db['Time'].iloc[metinfo_index], ['wind_dir']] = metinfo_db['Wind_Dir'].iloc[metinfo_index]\n",
    "\n",
    "    elif metinfo_index < index_end:\n",
    "        track.loc[(track['ts'] <= metinfo_db['Time'].iloc[metinfo_index]) & \\\n",
    "                   (track['ts'] > metinfo_db['Time'].iloc[metinfo_index - 1]), ['wind_spd']] = metinfo_db['Wind Speed'].iloc[metinfo_index]\n",
    "        track.loc[(track['ts'] <= metinfo_db['Time'].iloc[metinfo_index]) & \\\n",
    "                   (track['ts'] > metinfo_db['Time'].iloc[metinfo_index - 1]), ['wind_dir']] = metinfo_db['Wind_Dir'].iloc[metinfo_index]\n",
    "\n",
    "    else:\n",
    "        track.loc[track['ts'] > metinfo_db['Time'].iloc[metinfo_index], ['wind_spd']] = metinfo_db['Wind Speed'].iloc[metinfo_index]\n",
    "        track.loc[track['ts'] > metinfo_db['Time'].iloc[metinfo_index], ['wind_dir']] = metinfo_db['Wind_Dir'].iloc[metinfo_index]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot((track['ts']), track['wind_dir'])\n",
    "\n",
    "ax.set(xlabel='Time', ylabel='dir')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating head winds...')\n",
    "\n",
    "#delta_ang in degrees\n",
    "#wind_component in m/s\n",
    "track['delta_ang'] = track['true_hdg'] - track['wind_dir']\n",
    "track['headwind_comp'] = np.cos(deg2rad(track['delta_ang'])) * kt2ms(track['wind_spd'])\n",
    "track['airspeed'] = track['gs'] + track['headwind_comp']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates DRAG the power\n",
    "\n",
    "Todo: interface for Cd and Area; Vary rho per altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating power...')\n",
    "rho = 1.225 #fixed for now kg/m3\n",
    "Cd = 0.9 #fixed for me\n",
    "S = 0.516 #measure from photo m2\n",
    "track['drag'] = 0.5 * rho * track['airspeed']**2 * Cd * S\n",
    "track['drag_work'] = track['drag'] * track['dist'] #J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the potential energy work\n",
    "\n",
    "Todo: interface for cyclist and bike mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_mass = 80 #kg\n",
    "bike_mass = 10 #kg\n",
    "\n",
    "mass = cyclist_mass + bike_mass #kg\n",
    "g = 9.8 #m/s2\n",
    "track['pot_work'] = mass * g * track['delta_elev'] #J\n",
    "track['total_work'] = track['drag_work'] + track['pot_work'] #J\n",
    "track['power'] = track['total_work'] / (track['delta_t'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(track.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate averages and basic comparisons..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_work = track['total_work'].sum()\n",
    "pos_power_filter = track['total_work'] >= 0\n",
    "print('Total work was {:1.0f} Joules'.format(total_work))\n",
    "workout_time = track['ts'].iloc[-1]-track['ts'].iloc[0]\n",
    "print('Workout time was {}, or {:1.0f} seconds'.format(workout_time, workout_time.total_seconds()))\n",
    "print('Average overall power was {:1.0f} Watts'.format(total_work / workout_time.total_seconds()))\n",
    "print('Average positive power was {:1.0f} Watts'.format(track[track['total_work'] >= 0]['total_work'].sum() / workout_time.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print('execution time was {:0.1f} seconds'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "f, axarr = plt.subplots(3, sharex=True)\n",
    "axarr[0].plot((track['ts']),track['power'])\n",
    "\n",
    "axarr[0].set(ylabel='Power [W]',\n",
    "       title='Power Curve')\n",
    "axarr[0].grid()\n",
    "\n",
    "axarr[1].plot((track['ts']),track['elev'])\n",
    "\n",
    "axarr[1].set(ylabel='Elevation [m]',\n",
    "       title='Elevation Curve')\n",
    "axarr[1].grid()\n",
    "\n",
    "axarr[2].plot((track['ts']),track['headwind_comp'])\n",
    "\n",
    "axarr[2].set(xlabel='Time', ylabel='Wind Component [m/s]',\n",
    "       title='Head Wind Curve')\n",
    "axarr[2].grid()\n",
    "             \n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot((track['ts']),track['pot_work'])\n",
    "\n",
    "ax.set(xlabel='Time', ylabel='energy [J]',\n",
    "       title='Geopotential Work Curve')\n",
    "ax.grid()\n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "f, axarr = plt.subplots(4, sharex=True)\n",
    "axarr[0].plot((track['ts']),track['power'], alpha=0.8, linewidth=0.3)\n",
    "\n",
    "axarr[0].set(xlabel='Time', ylabel='Power [W]',\n",
    "       title='Power Curve')\n",
    "axarr[0].set_ylim([0, track['power'].max()])\n",
    "axarr[0].grid()\n",
    "\n",
    "axarr[1].plot((track['ts']),track['elev'])\n",
    "\n",
    "axarr[1].set(xlabel='Time', ylabel='Elevation [m]',\n",
    "       title='Elevation Curve')\n",
    "axarr[1].grid()\n",
    "\n",
    "axarr[2].plot((track['ts']),track['delta_ang'])\n",
    "\n",
    "axarr[2].set(xlabel='Time', ylabel='delta [deg]',\n",
    "       title='Wind Relative Angle Curve')\n",
    "axarr[2].grid()\n",
    "\n",
    "axarr[3].plot((track['ts']),track['delta_elev'])\n",
    "\n",
    "axarr[3].set(xlabel='Time', ylabel='[m]',\n",
    "       title='Delta Elev')\n",
    "axarr[3].grid()\n",
    "             \n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(4, sharex=True)\n",
    "\n",
    "color = 'tab:green'\n",
    "axarr[0].fill_between((track['ts']),track['elev'].min(),track['elev'], color=color, alpha=0.3)\n",
    "axarr[0].set_ylabel('Elevation [m]', color=color)\n",
    "#fill_between(x, 0, y1)\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2 = axarr[0].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.plot((track['ts']),track['power'], alpha=0.8, linewidth=0.3, color=color)\n",
    "\n",
    "ax2.set(xlabel='Time', title='Power and Elevation Curves')\n",
    "ax2.set_ylabel('Power [W]', color=color)\n",
    "ax2.set_ylim([0, track['power'].max()])\n",
    "ax2.grid()\n",
    "\n",
    "color = 'tab:red'\n",
    "axarr[1].plot((track['ts']),track['drag'], alpha=0.8, linewidth=0.3, color=color)\n",
    "\n",
    "\n",
    "axarr[1].set(title='Drag Curve')\n",
    "axarr[1].set_ylabel(ylabel='Drag [N]', color=color)\n",
    "axarr[1].grid()\n",
    "\n",
    "color = 'tab:blue'\n",
    "gs_kmh = ms2kmh(track['gs'])\n",
    "ax3 = axarr[1].twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax3.plot((track['ts']), gs_kmh, color=color, linewidth=0.3)\n",
    "ax3.set_ylabel('Ground Speed [km/h]', color=color)\n",
    "\n",
    "axarr[2].plot((track['ts']),ms2kmh(track['headwind_comp']))\n",
    "\n",
    "axarr[2].set(ylabel='head wind [km/h]',\n",
    "       title='Head Wind Curve')\n",
    "axarr[2].grid()\n",
    "\n",
    "axarr[3].plot((track['ts']),track['delta_elev'])\n",
    "\n",
    "axarr[3].set(xlabel='Time', ylabel='[m]',\n",
    "       title='Delta Elev')\n",
    "axarr[3].grid()\n",
    "             \n",
    "\n",
    "#fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track[track['total_work'] >= 0]\n",
    "ax = track[track['power']>=0]['power'].plot.hist(bins=30, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Bins/Time\n",
    "\n",
    "Let's plot now how many minutes was spent in each power bin.\n",
    "\n",
    "Change the power range and bin size below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_power = 0\n",
    "max_power = 1000\n",
    "power_bin_width = 50\n",
    "\n",
    "\n",
    "power_bins =  range(min_power, max_power, power_bin_width)\n",
    "track['power_bin'] = pd.cut(track['power'], power_bins)\n",
    "((track.groupby(['power_bin']).sum().loc[:,'delta_t'])/60).plot(kind='bar', title='Time [m] spent in power [W]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
